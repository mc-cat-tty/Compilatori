# Introduzione
## Memory wall
Moore's law vs DRMA growth: le performance delle DRAM crescono estremamente lentamente rispetto alle performance della CPU. Il cap aumenta nel tempo.

Nascono le cache per colmare il gap tra velocità di CPU e DRAM. Nel 1980 non esistevano cache, nel 1995 vengono introdotte le cache di doppio livello.

Le cache cercano di mantenere il numero di IPC alto. Idealmente 1:
- vero per istruzioni che usano ALU
- falso appena incontriamo un accesso in memoria (load/store)
Le cache aiutano a mantenere il IPC alto.

## DRAM
Problema: la DRAM è una memoria off-chip. Si trova distante dal SoC. Inoltre, è dinamica, ovvero i capacitori che compongono le rows (righe di bit) devono essere refreshati per mantenere la carica e, di conseguenza, l'informazione che trasportano.

>**Row**: unità minima organizzativa, rettangolare della DRAM. L'accesso viene fatto sull'intera riga di cache.

Le frequenze di refresh aumentano nel tempo:
- DRAM - Double Data Rate: refresh su entrambi i fronti
- QDR - Quad Data Rate: separazione dei canali di input e output

#Vedi metriche di performance della memoria: banda e latenza.

La banda può essere aumentata parallelizzando la lettura: trasferimento di bit della stessa riga parallelamente. Viene chiamata **burst mode**.

## SRAM
>Static RAM: memoria composta da transistor (non capacitori come sopra). Ogni cella è composta da 6 transistor MOS, che formano un flip-flop.

Vantaggi:
- high density
- fast access time
- high cost

La SRAM è fisicamente distribuita. Eg. L3$ corre su tutto il chip, circondando i vari core.

#Ricorda la distinzione tra *instruction* e *data* cache. Permette la realizzazione di una architettura di Harvard.

## Gerarchie di memoria
>Blocco o linea: unità della copia. Può essere formata da più word.

- cache miss: il dato non si trova sulla cache di livello più alto, fallisce il fetch dalla cache, paga la penalità di caricare una nuova riga di cache
- cache hit: il dato si trova in cache

## Località
>**Località spaziale**: i programmi spendono la maggior parte del tempo nei loop. I loop tipicamente accedono a strutture dati contigue in memoria.
>**Località temporale**: fatto un accesso ad un blocco, probabilmente verrà riacceduto in futuro.

#Vedi *Program reconstructing for virtual memory*. IBM System Journal.

## Cache misses
Esistono 3 tipi di cache nei processori single-core:
- **cold cache** (compulsory): succede a sistema freddo
- **conflict**: succede nelle cache direct mapped, quando due indirizzi vorrebbero essere cachati allo stesso indice (index bits).
- **capacity**: Le cache completamente associative non usano index bits. Possono comunque finire il numero di linee di cache libere. Anche questo è un tipo di miss.

## Cache schemes
Nella realtà si usano cache **set associative**: cache che mischiano entrambe le strategie. La componente direct mapped fornisce il set di linee individuate dallo stesso indirizzo (in particolare, dagli index bits). Eg. una cache 2-way set associative usa gli index bits per recuperare un set di 2 linee, confrontando poi (parte associativa) l'effettivo indirizzo in memoria.

Più lo schema è associativo, meglio utilizzo lo spazio. Ma rendo lo schema più costoso, dato dal numero di comparatori.

## Block sizes
Linee di cache di grandi dimensioni, permettono di sfruttare meglio il principio di località spaziale. Ma riducono il numero di linee disponibili, alzando la pollution (eviction dovuta a un conflitto).
## Cache snooping
>Schema nel quale uno snooper (o coherency controller) monitora gli accessi in memoria la fine di mantenere coerenti le cache di un sistema distribuito..

# Memory optimizations
## Riuso e località
>**Data reuse**: dati vicini sono usati più volte. Sfrutta località temporale.

Pensa ad esempio alle moltiplicazioni matriciali, in cui una riga i viene usata più volte per calcolare gli elementi (i, j), (i, j+1), ...
## Classi di variabili
- **scalari**: eg. variabili intere
- **strutture e puntatori**
- **array**: lasciano più margine di manovra
### Scalari
Tre tipi: locali, globali, argomenti

Le variabili scalari sono memorizzate in registri. Nell'intermedio ottenuti con mem2reg, sotto l'assunzione che esista un numero illimitato di registri (se non conosco la struttura del **register file**). Il suo duale, reg2mem viene usato per riportare la gestione della memoria nell'intermedio.
### Strutture e puntatori
Problema: campi che cadono su più row, mi costringono a carica più row, dove non è strettamente necessario.

Soluzioni:
- **layout alignment**
- **padding**: se non è possibile con semplici riordini, aggiungo dummy bytes per spingere l'allineamento alle parole di macchina

```c
struct {
	int count;
	double velocity;
	double inertia;
	struct node neigh[N];
}

for (int i=0; i<N; i++) {
	total_count += neigh[i].count;
}
```
Problema: ho un accesso ripetuto a linee diverse, sulle quali accedo al primo campo.
Soluzione: il compilatore potrebbe spezzare la struttura dati, smembrandola, per fare stare tutti i count sulla stessa linea.